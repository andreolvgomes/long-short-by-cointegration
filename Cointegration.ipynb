{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Cointegrated Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procura e prepara pares cointegrados e organiza um DataFrame com todas as informações para serem analisadas e decisão de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile Cointegration.py\n",
    "#https://medium.com/@bart.chr/pairs-trading-for-algorithmic-trading-breakdown-d8b709f59372\n",
    "#https://github.com/aconstandinou/mean-reversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions/Methods\n",
    "\n",
    "Salva as funções em Cointegration.py para serem usadas em outros notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile Cointegration.py\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.stattools as ts \n",
    "from statsmodels.tsa.stattools import coint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "Augmented Dickey–Fuller (ADF) unit root test; p-value < .05\n",
    "\"\"\"\n",
    "class DickeyFuller(object):\n",
    "    def __init__(self, significance=.05):\n",
    "        self.significance_level = significance\n",
    "        self.p_value = None\n",
    "        self.perc_stat = None\n",
    "        self.is_stationary = None\n",
    "        \n",
    "    def check(self, time_series):\n",
    "        model = ts.adfuller(time_series, 1)\n",
    "        self.p_value = model[1]\n",
    "        statistic = model[0]\n",
    "        \n",
    "        # Dickey-Fuller\n",
    "        self.is_stationary = False\n",
    "        if (self.p_value < self.significance_level):\n",
    "            self.is_stationary = True\n",
    "        \n",
    "        # Augmented Dickey Fuller (ADF)\n",
    "        if (abs(statistic) > abs(model[4]['1%'])):\n",
    "            self.perc_stat = 99\n",
    "        elif (abs(statistic) > abs(model[4]['5%'])):\n",
    "            self.perc_stat = 95\n",
    "        elif (abs(statistic) > abs(model[4]['10%'])):\n",
    "            self.perc_stat = 90\n",
    "        else:\n",
    "            self.perc_stat = 0\n",
    "\n",
    "        return self.is_stationary\n",
    "\n",
    "\"\"\"\n",
    "Half Life test from the Ornstein-Uhlenbeck process \n",
    "\"\"\"\n",
    "class HalfLife(object):\n",
    "    def __init__(self):\n",
    "        self.half_life = None\n",
    "\n",
    "    def check(self, time_series):\n",
    "        lag = np.roll(time_series, 1)\n",
    "        lag[0] = 0\n",
    "        ret = time_series - lag\n",
    "        ret[0] = 0\n",
    "\n",
    "        # adds intercept terms to X variable for regression\n",
    "        lag2 = sm.add_constant(lag)\n",
    "        res = sm.OLS(ret, lag2).fit()\n",
    "        self.half_life = int(round(-np.log(2) / res.params[1],0))\n",
    "\n",
    "        if self.half_life <= 0:\n",
    "            self.half_life = 1\n",
    "        return self.half_life\n",
    "\n",
    "\"\"\"\n",
    "If Hurst Exponent is under the 0.5 value of a random walk, then the series is mean reverting\n",
    "\"\"\"\n",
    "class HurstExponent():\n",
    "    def __init__(self):\n",
    "        self.h_min = 0.0\n",
    "        self.h_max = 0.4\n",
    "        self.look_back = 126\n",
    "        #https://robotwealth.com/demystifying-the-hurst-exponent-part-1/\n",
    "        self.lag_max = 20#era 100\n",
    "        self.h_value = None\n",
    "    \n",
    "    def check(self, time_series):\n",
    "        lags = range(2, self.lag_max)\n",
    "\n",
    "        tau = [np.sqrt(np.std(np.subtract(time_series[lag:], time_series[:-lag]))) for lag in lags]\n",
    "        poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "\n",
    "        self.h_value = poly[0]*2.0 \n",
    "        return self.h_value\n",
    "\n",
    "def model_ols(y, x):\n",
    "    x = sm.add_constant(x)\n",
    "    model = sm.OLS(y, x).fit()\n",
    "    return model\n",
    "\n",
    "# beta/coeficiente angular\n",
    "def beta(y, x):\n",
    "    model = model_ols(y, x)\n",
    "    return model.params[1]\n",
    "\n",
    "\"\"\"\n",
    "Check cointegrated pairs from dataframe\n",
    "\"\"\"\n",
    "def find_cointegrated_pairs(data, period=250, check_other_periods=True):\n",
    "    rows = []\n",
    "    index=-1\n",
    "    \n",
    "    for y_symbol in data.columns:\n",
    "        index = index + 1\n",
    "        for x_symbol in data.columns[index+1:data.shape[1]]:#for x_symbol in data.columns:\n",
    "            if (y_symbol == x_symbol):\n",
    "                continue\n",
    "                \n",
    "            y_values = data[y_symbol]\n",
    "            x_values = data[x_symbol]\n",
    "            \n",
    "            # filter by period\n",
    "            y, x = getvalues_by_period(y_values, x_values, period)\n",
    "            coint = cointegration(y, x, 0)\n",
    "            \n",
    "            # check is stationary\n",
    "            if (coint['is_stationary'] == True):\n",
    "                rows.append([len(x), y_symbol, x_symbol, coint['p_value'], coint['perc_stat'], coint['beta']])\n",
    "                \n",
    "            # 28/06/2020\n",
    "            # se não tá cointegrado no período principal, verifica se tá em outro\n",
    "            if (coint['is_stationary'] == False and check_other_periods == True):\n",
    "                for per in [250, 240, 220, 200, 180, 160, 140, 120, 100]:\n",
    "                    res_dic = cointegration(y_values, x_values, per)\n",
    "\n",
    "                    # só precisa saber que tá cointregado em algum período\n",
    "                    if (res_dic['is_stationary'] == True):\n",
    "                        rows.append([per, y_symbol, x_symbol, res_dic['p_value'], res_dic['perc_stat'], res_dic['beta']])\n",
    "                        break\n",
    "\n",
    "    # create DataFrame\n",
    "    df_pairs = pd.DataFrame(rows, columns=['Period', 'Dependente', 'Independente', 'Dickey-Fuller', 'ADF', 'Beta'])\n",
    "    return df_pairs\n",
    "\n",
    "\"\"\"\n",
    "Check cointegration in values Y vs X by period\n",
    "\"\"\"\n",
    "def cointegration(y, x, period = 250):\n",
    "    adf = DickeyFuller()\n",
    "    if (period == 0):\n",
    "        period = len(y)\n",
    "\n",
    "    y, x = getvalues_by_period(y, x, period)\n",
    "    model = model_ols(y, x)\n",
    "    adf.check(model.resid)\n",
    "    return {\"is_stationary\": adf.is_stationary,\n",
    "            \"p_value\": adf.p_value,\n",
    "            \"perc_stat\": adf.perc_stat,\n",
    "            \"beta\": model.params[1],\n",
    "            \"coefang\": model.params[1],\n",
    "            \"coeflinear\": model.params[0],\n",
    "            \"period\": period}\n",
    "\n",
    "\"\"\"\n",
    "Apply various periods in DataFrame of the pairs\n",
    "\"\"\"\n",
    "def apply_periods(data, pairs):\n",
    "    pairs['PeriodQt'] = 0\n",
    "    pairs['PeriodStr'] = ''\n",
    "    for i, row in pairs.iterrows():\n",
    "        y = data[row['Dependente']]\n",
    "        x = data[row['Independente']]\n",
    "        analysis = analysis_by_periods(y, x)\n",
    "        stationary = analysis.loc[(analysis['Stationary'])]\n",
    "\n",
    "        des = ''\n",
    "        for j, row in stationary.iterrows():\n",
    "            if (des!=''):\n",
    "                des=des+','\n",
    "            des=des+str(row['Period'])\n",
    "\n",
    "        pairs['PeriodQt'].iloc[i] = stationary.shape[0]\n",
    "        pairs['PeriodStr'].iloc[i] = des\n",
    "\n",
    "\"\"\"\n",
    "Check analysis of the periods: 100, 120, 140, 160 ... 250\n",
    "\"\"\"\n",
    "def analysis_by_periods(y, x):\n",
    "    rows=[]\n",
    "    adf = DickeyFuller()\n",
    "    \n",
    "    for period in [100, 120, 140, 160, 180, 200, 220, 240, 250]:\n",
    "        # filter by period\n",
    "        y_values, x_values = getvalues_by_period(y, x, period)\n",
    "\n",
    "        res_dic = cointegration(y_values, x_values, 0)\n",
    "        half_life = check_halflife(y_values, x_values)\n",
    "        hurst = check_hurst(y_values, x_values)\n",
    "        corr = corr_pearson(y_values, x_values)\n",
    "\n",
    "        rows.append([period, res_dic['is_stationary'], res_dic['p_value'], res_dic['perc_stat'], res_dic['beta'], half_life, hurst, corr])\n",
    "        \n",
    "    analysis = pd.DataFrame(rows, columns=['Period', 'Stationary', 'Dickey-Fuller', 'ADF', 'Beta', 'HalfLife', 'Hurst', 'Corr'])\n",
    "    return analysis\n",
    "\n",
    "\"\"\"\n",
    "Return em log\n",
    "\"\"\"\n",
    "def return_varlog(time_series):\n",
    "    lag = np.roll(time_series, 1)\n",
    "    lag[0] = 0\n",
    "    ret = np.log(time_series/lag)\n",
    "    ret[0] = 0\n",
    "    return ret\n",
    "\n",
    "\"\"\"\n",
    "Apply half-life\n",
    "\"\"\"\n",
    "def apply_halflife(data, pairs, period = 250):\n",
    "    pairs['HalfLife'] = 0\n",
    "    \n",
    "    for i, row in pairs.iterrows():\n",
    "        y, x = getvalues_by_period(data[row['Dependente']], data[row['Independente']], period)\n",
    "        \n",
    "        value = check_halflife(y, x)\n",
    "        pairs['HalfLife'].iloc[i]=value\n",
    "\n",
    "\"\"\"\n",
    "Check and return half-life\n",
    "\"\"\"\n",
    "def check_halflife(y, x):\n",
    "    halflile = HalfLife()\n",
    "    model = model_ols(y, x)\n",
    "    return halflile.check(model.resid)\n",
    "\n",
    "\"\"\"\n",
    "Apply hurst coefficient\n",
    "\"\"\"\n",
    "def apply_hurst(data, pairs, period=250):\n",
    "    pairs['Hurst'] = 0\n",
    "    \n",
    "    for i, row in pairs.iterrows():\n",
    "        y = data[row['Dependente']]\n",
    "        x = data[row['Independente']]\n",
    "        y, x = getvalues_by_period(y, x, period)\n",
    "            \n",
    "        value = check_hurst(y, x)\n",
    "        pairs['Hurst'].iloc[i]= value\n",
    "\n",
    "\"\"\"\n",
    "Check and return hurst coefficient\n",
    "\"\"\"\n",
    "def check_hurst(y, x):\n",
    "    hurst = HurstExponent()\n",
    "    model = model_ols(y, x)\n",
    "    return hurst.check(model.resid.values)\n",
    "\n",
    "# 0.9 para mais ou para menos indica uma correlação muito forte.\n",
    "# 0.7 a 0.9 positivo ou negativo indica uma correlação forte.percorre\n",
    "# 0.5 a 0.7 positivo ou negativo indica uma correlação moderada.\n",
    "# 0.3 a 0.5 positivo ou negativo indica uma correlação fraca.\n",
    "# 0 a 0.3 positivo ou negativo indica uma correlação desprezível.'''\n",
    "def corr_pearson(y, x, inlog=False):\n",
    "    if inlog:\n",
    "        y = return_varlog(y)\n",
    "        x = return_varlog(x)\n",
    "    \n",
    "    y_avg, x_avg = np.average(y), np.average(x)\n",
    "    y_stdev, x_stdev = np.std(y), np.std(x)\n",
    "    n = len(y)\n",
    "    denominator = y_stdev * x_stdev * n\n",
    "    numerator = np.sum(np.multiply(y-y_avg, x-x_avg))\n",
    "    p_coef = numerator/denominator\n",
    "    return p_coef\n",
    "\n",
    "\"\"\"\n",
    "Apply correlation in DataFrame of the pairs\n",
    "\"\"\"\n",
    "def apply_corr(data, pairs, period=250):\n",
    "    pairs['Corr'] = 0\n",
    "    \n",
    "    for i, row in pairs.iterrows():\n",
    "        y = data[row['Dependente']]\n",
    "        x = data[row['Independente']]\n",
    "        y, x = getvalues_by_period(y, x, period)\n",
    "            \n",
    "        corr = corr_pearson(y, x, True)\n",
    "        pairs['Corr'].iloc[i] = corr\n",
    "\n",
    "\"\"\"\n",
    "Check signal\n",
    "\"\"\"\n",
    "def signal(y, x):\n",
    "    model = model_ols(y, x)\n",
    "    std = statistics.stdev(model.resid)\n",
    "    resi_curr = model.resid.iloc[-1]\n",
    "    zscore_up = 2*std\n",
    "    zscore_down = -2*std\n",
    "    zcurrent = 0\n",
    "    desc = ''\n",
    "    \n",
    "    # >0; resíduo acima da linha 0\n",
    "    if(resi_curr > 0):\n",
    "        desc = 'Short/Long'\n",
    "        zcurrent = zscore_up\n",
    "    else:\n",
    "        desc = 'Long/Short'\n",
    "        zcurrent = zscore_down\n",
    "    \n",
    "    percent = (abs(resi_curr)/abs(zcurrent))\n",
    "    #1-descr\n",
    "    #2-resíduo atual\n",
    "    #3-percent distância da linha 0, quanto maior, melhor\n",
    "    return [desc, resi_curr, percent]\n",
    "\n",
    "\"\"\"\n",
    "Apply signal in DataFrame of the pairs\n",
    "\"\"\"\n",
    "def apply_signal(data, pairs, period=250):\n",
    "    pairs['Signal'] = 0\n",
    "    pairs['SignalStr'] = ''\n",
    "    \n",
    "    for i, row in pairs.iterrows():\n",
    "        y, x = getvalues_by_period(data[row['Dependente']], data[row['Independente']], period)\n",
    "        \n",
    "        sig = signal(y, x)\n",
    "        pairs['Signal'].iloc[i] = sig[2]\n",
    "        pairs['SignalStr'].iloc[i] = sig[0]\n",
    "\n",
    "\"\"\"\n",
    "Check periods\n",
    "\"\"\"\n",
    "def check_periods(data, y_symbol, x_symbol, period):\n",
    "    if (type(period) is int):\n",
    "        return check_oneperiod(data, y_symbol, x_symbol, period)\n",
    "    if (type(period) is list):\n",
    "        rows=[]\n",
    "        for p in period:\n",
    "            res = check_oneperiod(data, y_symbol, x_symbol, p)\n",
    "            rows.append([res[0], res[1]])\n",
    "        return rows\n",
    "\n",
    "\"\"\"\n",
    "Check a single period\n",
    "\"\"\"\n",
    "def check_oneperiod(data, y_symbol, x_symbol, period):\n",
    "    y, x = getvalues_by_period(data[y_symbol], data[x_symbol], period)\n",
    "    \n",
    "    adf = DickeyFuller()\n",
    "    model = model_ols(y, x)\n",
    "    adf.check(model.resid)\n",
    "    beta = model.params[1]\n",
    "\n",
    "    return [adf.p_value, adf.is_stationary]\n",
    "\n",
    "\"\"\"\n",
    "Search and return values by period\n",
    "\"\"\"\n",
    "def getvalues_by_period(y, x, period):\n",
    "    if(period <= 0):\n",
    "        return y, x\n",
    "    \n",
    "    n = len(y)\n",
    "    if(period < n):\n",
    "        pos = n-period\n",
    "        y = y.iloc[pos:]\n",
    "        x = x.iloc[pos:]\n",
    "    return y, x\n",
    "\n",
    "\"\"\"\n",
    "Standardize by z-score\n",
    "\"\"\"\n",
    "def zscore(series):\n",
    "    return (series - series.mean()) / np.std(series)\n",
    "\n",
    "\"\"\"\n",
    "Limpar pasta da imagem\n",
    "\"\"\"\n",
    "def clear_folder(pathdir):\n",
    "    for file in os.listdir(pathdir):\n",
    "        filename = '{}/{}'.format(pathdir, file)\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "\n",
    "def volatility(prices, periods=0):\n",
    "    if (periods > 0):\n",
    "        prices = prices[0:periods+1]# +1, pq haverá um lag(d-1)\n",
    "    log = np.log(prices/prices.shift(1))\n",
    "    vol = log.std() * np.sqrt(252)\n",
    "    return vol\n",
    "\n",
    "\"\"\"\n",
    "Show graphic\n",
    "\"\"\"\n",
    "def show(data, y_symbol, x_symbol, period=250, padronizar=True, savefig=''):\n",
    "    y, x = getvalues_by_period(data[y_symbol], data[x_symbol], period)\n",
    "    \n",
    "    model= model_ols(y, x)\n",
    "    result = model.resid\n",
    "    \n",
    "    # padronizar porque a taxa absoluta pode não ser a maneira mais ideal de analisar\n",
    "    if(padronizar):\n",
    "        result = zscore(model.resid)\n",
    "        \n",
    "    std = statistics.stdev(result)\n",
    "    entry_threshold = 2 # entrada em 2 desvio padrão\n",
    "    \n",
    "    result.plot(figsize=(15,6))\n",
    "    plt.ylabel('Residual')\n",
    "    if(y_symbol != '' and x_symbol != ''):\n",
    "        plt.title('{} / {}'.format(y_symbol, x_symbol))\n",
    "\n",
    "    #purple\n",
    "    plt.axhline(0, color='black',label='mean') # Add the mean of residual\n",
    "    plt.axhline(entry_threshold*std, color='red', linestyle='--', linewidth=2)\n",
    "    plt.axhline(-entry_threshold*std, color='green', linestyle='--', linewidth=2)\n",
    "    plt.xlabel('')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.margins(0.1)\n",
    "    if(savefig!=''):\n",
    "        plt.savefig(savefig)\n",
    "\n",
    "    #plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_cart = 'datasets/data_cart.csv'\n",
    "path_data_full = 'datasets/data.csv'\n",
    "path_data_alpha = 'datasets/data_alpha.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 71), 'from 17/04/2019 to 01/07/2020')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_data_cart, index_col=0)\n",
    "#df = df[:-1].copy()\n",
    "data = df[df.columns.difference(['Data', 'Date'])]\n",
    "data.shape, 'from {} to {}'.format(data.index[0], data.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Dependente</th>\n",
       "      <th>Independente</th>\n",
       "      <th>Dickey-Fuller</th>\n",
       "      <th>ADF</th>\n",
       "      <th>Beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>ABEV3</td>\n",
       "      <td>BBAS3</td>\n",
       "      <td>0.033068</td>\n",
       "      <td>95</td>\n",
       "      <td>0.300165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>ABEV3</td>\n",
       "      <td>BBDC3</td>\n",
       "      <td>0.043536</td>\n",
       "      <td>95</td>\n",
       "      <td>0.434465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>ABEV3</td>\n",
       "      <td>BBDC4</td>\n",
       "      <td>0.018765</td>\n",
       "      <td>95</td>\n",
       "      <td>0.409116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>ABEV3</td>\n",
       "      <td>BBSE3</td>\n",
       "      <td>0.047385</td>\n",
       "      <td>95</td>\n",
       "      <td>0.605446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>ABEV3</td>\n",
       "      <td>BRDT3</td>\n",
       "      <td>0.048368</td>\n",
       "      <td>95</td>\n",
       "      <td>0.606020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1051</td>\n",
       "      <td>220</td>\n",
       "      <td>UGPA3</td>\n",
       "      <td>USIM5</td>\n",
       "      <td>0.035635</td>\n",
       "      <td>95</td>\n",
       "      <td>2.110841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1052</td>\n",
       "      <td>250</td>\n",
       "      <td>UGPA3</td>\n",
       "      <td>VIVT4</td>\n",
       "      <td>0.024903</td>\n",
       "      <td>95</td>\n",
       "      <td>0.801399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1053</td>\n",
       "      <td>100</td>\n",
       "      <td>UGPA3</td>\n",
       "      <td>WEGE3</td>\n",
       "      <td>0.037265</td>\n",
       "      <td>95</td>\n",
       "      <td>0.498010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1054</td>\n",
       "      <td>250</td>\n",
       "      <td>USIM5</td>\n",
       "      <td>VIVT4</td>\n",
       "      <td>0.013537</td>\n",
       "      <td>95</td>\n",
       "      <td>0.359174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1055</td>\n",
       "      <td>250</td>\n",
       "      <td>VALE3</td>\n",
       "      <td>VVAR3</td>\n",
       "      <td>0.040938</td>\n",
       "      <td>95</td>\n",
       "      <td>0.895724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1056 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Period Dependente Independente  Dickey-Fuller  ADF      Beta\n",
       "0        250      ABEV3        BBAS3       0.033068   95  0.300165\n",
       "1        250      ABEV3        BBDC3       0.043536   95  0.434465\n",
       "2        250      ABEV3        BBDC4       0.018765   95  0.409116\n",
       "3        250      ABEV3        BBSE3       0.047385   95  0.605446\n",
       "4        250      ABEV3        BRDT3       0.048368   95  0.606020\n",
       "...      ...        ...          ...            ...  ...       ...\n",
       "1051     220      UGPA3        USIM5       0.035635   95  2.110841\n",
       "1052     250      UGPA3        VIVT4       0.024903   95  0.801399\n",
       "1053     100      UGPA3        WEGE3       0.037265   95  0.498010\n",
       "1054     250      USIM5        VIVT4       0.013537   95  0.359174\n",
       "1055     250      VALE3        VVAR3       0.040938   95  0.895724\n",
       "\n",
       "[1056 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = find_cointegrated_pairs(data)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Half-Life applied successfully\n"
     ]
    }
   ],
   "source": [
    "apply_halflife(data, pairs)\n",
    "print('Half-Life applied successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurst applied successfully\n"
     ]
    }
   ],
   "source": [
    "apply_hurst(data, pairs)\n",
    "print('Hurst applied successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation applied successfully\n"
     ]
    }
   ],
   "source": [
    "apply_corr(data, pairs)\n",
    "print('Correlation applied successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal applied successfully\n"
     ]
    }
   ],
   "source": [
    "apply_signal(data, pairs)\n",
    "print('Signal applied successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_periods(data, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.to_csv('datasets/cointegrated_pairs.csv', index=False)\n",
    "print('Saved successfully!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo\n",
    "Agora é só usar o cointegrated_pairs.csv para fazer as diversas análises que desejar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.read_csv('datasets/cointegrated_pairs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste de visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(data, pairs['Dependente'][0], pairs['Independente'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Cointegrated Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procura e prepara pares cointegrados e organiza um DataFrame com todas as informações para serem analisadas e decisão de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile Cointegration.py\n",
    "#https://medium.com/@bart.chr/pairs-trading-for-algorithmic-trading-breakdown-d8b709f59372\n",
    "#https://github.com/aconstandinou/mean-reversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions/Methods\n",
    "\n",
    "Salva as funções em Cointegration.py para serem usadas em outros notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile Cointegration.py\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.stattools as ts \n",
    "from statsmodels.tsa.stattools import coint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "Augmented Dickey–Fuller (ADF) unit root test; p-value < .05\n",
    "\"\"\"\n",
    "class DickeyFuller(object):\n",
    "    def __init__(self, significance=.05):\n",
    "        self.significance_level = significance\n",
    "        self.p_value = None\n",
    "        self.perc_stat = None\n",
    "        self.is_stationary = None\n",
    "        self.statistic = None\n",
    "        \n",
    "    def check(self, time_series):\n",
    "        model = ts.adfuller(time_series, 1)\n",
    "        self.p_value = model[1]\n",
    "        self.statistic = model[0]\n",
    "        \n",
    "        # Dickey-Fuller\n",
    "        self.is_stationary = False\n",
    "        if (self.p_value < self.significance_level):\n",
    "            self.is_stationary = True\n",
    "        \n",
    "        # Augmented Dickey Fuller (ADF)\n",
    "        if (abs(self.statistic) > abs(model[4]['1%'])):\n",
    "            self.perc_stat = 99\n",
    "        elif (abs(self.statistic) > abs(model[4]['5%'])):\n",
    "            self.perc_stat = 95\n",
    "        elif (abs(self.statistic) > abs(model[4]['10%'])):\n",
    "            self.perc_stat = 90\n",
    "        else:\n",
    "            self.perc_stat = 0\n",
    "\n",
    "        return self.is_stationary\n",
    "\n",
    "\"\"\"\n",
    "Half Life test from the Ornstein-Uhlenbeck process \n",
    "\"\"\"\n",
    "class HalfLife(object):\n",
    "    def __init__(self):\n",
    "        self.half_life = None\n",
    "\n",
    "    def check(self, time_series):\n",
    "        lag = np.roll(time_series, 1)\n",
    "        lag[0] = 0\n",
    "        ret = time_series - lag\n",
    "        ret[0] = 0\n",
    "\n",
    "        # adds intercept terms to X variable for regression\n",
    "        lag2 = sm.add_constant(lag)\n",
    "        res = sm.OLS(ret, lag2).fit()\n",
    "        self.half_life = int(round(-np.log(2) / res.params[1],0))\n",
    "\n",
    "        if self.half_life <= 0:\n",
    "            self.half_life = 1\n",
    "        return self.half_life\n",
    "\n",
    "\"\"\"\n",
    "If Hurst Exponent is under the 0.5 value of a random walk, then the series is mean reverting\n",
    "\"\"\"\n",
    "class HurstExponent():\n",
    "    def __init__(self):\n",
    "        self.h_min = 0.0\n",
    "        self.h_max = 0.4\n",
    "        self.look_back = 126\n",
    "        #https://robotwealth.com/demystifying-the-hurst-exponent-part-1/\n",
    "        self.lag_max = 20#era 100\n",
    "        self.h_value = None\n",
    "    \n",
    "    def check(self, time_series):\n",
    "        lags = range(2, self.lag_max)\n",
    "\n",
    "        tau = [np.sqrt(np.std(np.subtract(time_series[lag:], time_series[:-lag]))) for lag in lags]\n",
    "        poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "\n",
    "        self.h_value = poly[0]*2.0 \n",
    "        return self.h_value\n",
    "\n",
    "def model_ols(y, x):\n",
    "    x = sm.add_constant(x)\n",
    "    model = sm.OLS(y, x).fit()\n",
    "    return model\n",
    "\n",
    "# beta/coeficiente angular\n",
    "def beta(y, x):\n",
    "    model = model_ols(y, x)\n",
    "    return model.params[1]\n",
    "\n",
    "\"\"\"\n",
    "Check cointegrated pairs from dataframe\n",
    "\"\"\"\n",
    "def find_cointegrated_pairs(data, period=250, check_other_periods=True):\n",
    "    rows = []\n",
    "    index=-1\n",
    "    \n",
    "    for y_symbol in data.columns:\n",
    "        index = index + 1\n",
    "        for x_symbol in data.columns[index+1:data.shape[1]]:#for x_symbol in data.columns:\n",
    "            if (y_symbol == x_symbol):\n",
    "                continue\n",
    "                \n",
    "            y_values = data[y_symbol]\n",
    "            x_values = data[x_symbol]\n",
    "            \n",
    "            # filter by period\n",
    "            y, x = getvalues_by_period(y_values, x_values, period)\n",
    "            coint = cointegration(y, x, 0)\n",
    "            \n",
    "            # check is stationary\n",
    "            if (coint['is_stationary'] == True):\n",
    "                rows.append([len(x), y_symbol, x_symbol, coint['statistic'], coint['perc_stat'], coint['beta'], coint['std']])\n",
    "                \n",
    "            # 28/06/2020\n",
    "            # se não tá cointegrado no período principal, verifica se tá em outro\n",
    "            if (coint['is_stationary'] == False and check_other_periods == True):\n",
    "                for per in [250, 240, 220, 200, 180, 160, 140, 120, 100]:\n",
    "                    res_dic = cointegration(y_values, x_values, per)\n",
    "\n",
    "                    # só precisa saber que tá cointregado em algum período\n",
    "                    if (res_dic['is_stationary'] == True):\n",
    "                        rows.append([per, y_symbol, x_symbol, res_dic['statistic'], res_dic['perc_stat'], res_dic['beta'], res_dic['std']])\n",
    "                        break\n",
    "\n",
    "    # create DataFrame\n",
    "    df_pairs = pd.DataFrame(rows, columns=['Period', 'Dependente', 'Independente', 'Dickey-Fuller', 'ADF', 'Beta', \"Std\"])\n",
    "    return df_pairs\n",
    "\n",
    "\"\"\"\n",
    "Check cointegration in values Y vs X by period\n",
    "\"\"\"\n",
    "def cointegration(y, x, period = 250):\n",
    "    adf = DickeyFuller()\n",
    "    if (period == 0):\n",
    "        period = len(y)\n",
    "\n",
    "    y, x = getvalues_by_period(y, x, period)\n",
    "    model = model_ols(y, x)\n",
    "    adf.check(model.resid)\n",
    "    return {\"is_stationary\": adf.is_stationary,\n",
    "            \"p_value\": adf.p_value,\n",
    "            \"std\": abs(zscore(model.resid)[-1]),\n",
    "            \"perc_stat\": adf.perc_stat,\n",
    "            \"statistic\": adf.statistic,\n",
    "            \"beta\": model.params[1],\n",
    "            \"coefang\": model.params[1],\n",
    "            \"coeflinear\": model.params[0],\n",
    "            \"period\": period}\n",
    "\n",
    "\"\"\"\n",
    "Apply various periods in DataFrame of the pairs\n",
    "\"\"\"\n",
    "def apply_periods(data, pairs):\n",
    "    pairs['PeriodQt'] = 0\n",
    "    pairs['PeriodStr'] = ''\n",
    "    for i, row in pairs.iterrows():\n",
    "        y = data[row['Dependente']]\n",
    "        x = data[row['Independente']]\n",
    "        analysis = analysis_by_periods(y, x)\n",
    "        stationary = analysis.loc[(analysis['Stationary'])]\n",
    "\n",
    "        des = ''\n",
    "        for j, row in stationary.iterrows():\n",
    "            if (des!=''):\n",
    "                des=des+','\n",
    "            des=des+str(row['Period'])\n",
    "\n",
    "        pairs['PeriodQt'].iloc[i] = stationary.shape[0]\n",
    "        pairs['PeriodStr'].iloc[i] = des\n",
    "\n",
    "\"\"\"\n",
    "Check analysis of the periods: 100, 120, 140, 160 ... 250\n",
    "\"\"\"\n",
    "def analysis_by_periods(y, x):\n",
    "    rows=[]\n",
    "    adf = DickeyFuller()\n",
    "    \n",
    "    for period in [100, 120, 140, 160, 180, 200, 220, 240, 250]:\n",
    "        # filter by period\n",
    "        y_values, x_values = getvalues_by_period(y, x, period)\n",
    "\n",
    "        res_dic = cointegration(y_values, x_values, 0)\n",
    "        half_life = check_halflife(y_values, x_values)\n",
    "        hurst = check_hurst(y_values, x_values)\n",
    "        corr = corr_pearson(y_values, x_values)\n",
    "\n",
    "        rows.append([period, res_dic['is_stationary'], res_dic['statistic'], res_dic['perc_stat'], res_dic['beta'], half_life, hurst, corr])\n",
    "        \n",
    "    analysis = pd.DataFrame(rows, columns=['Period', 'Stationary', 'Dickey-Fuller', 'ADF', 'Beta', 'HalfLife', 'Hurst', 'Corr'])\n",
    "    return analysis\n",
    "\n",
    "\"\"\"\n",
    "Return em log\n",
    "\"\"\"\n",
    "def return_varlog(time_series):\n",
    "    lag = np.roll(time_series, 1)\n",
    "    lag[0] = 0\n",
    "    ret = np.log(time_series/lag)\n",
    "    ret[0] = 0\n",
    "    return ret\n",
    "\n",
    "\"\"\"\n",
    "Apply half-life\n",
    "\"\"\"\n",
    "def apply_halflife(data, pairs, period = 250):\n",
    "    pairs['HalfLife'] = 0\n",
    "    \n",
    "    for i, row in pairs.iterrows():\n",
    "        y, x = getvalues_by_period(data[row['Dependente']], data[row['Independente']], period)\n",
    "        \n",
    "        value = check_halflife(y, x)\n",
    "        pairs['HalfLife'].iloc[i]=value\n",
    "\n",
    "\"\"\"\n",
    "Check and return half-life\n",
    "\"\"\"\n",
    "def check_halflife(y, x):\n",
    "    halflile = HalfLife()\n",
    "    model = model_ols(y, x)\n",
    "    return halflile.check(model.resid)\n",
    "\n",
    "\"\"\"\n",
    "Apply hurst coefficient\n",
    "\"\"\"\n",
    "def apply_hurst(data, pairs, period=250):\n",
    "    pairs['Hurst'] = 0\n",
    "    \n",
    "    for i, row in pairs.iterrows():\n",
    "        y = data[row['Dependente']]\n",
    "        x = data[row['Independente']]\n",
    "        y, x = getvalues_by_period(y, x, period)\n",
    "            \n",
    "        value = check_hurst(y, x)\n",
    "        pairs['Hurst'].iloc[i]= value\n",
    "\n",
    "\"\"\"\n",
    "Check and return hurst coefficient\n",
    "\"\"\"\n",
    "def check_hurst(y, x):\n",
    "    hurst = HurstExponent()\n",
    "    model = model_ols(y, x)\n",
    "    return hurst.check(model.resid.values)\n",
    "\n",
    "# 0.9 para mais ou para menos indica uma correlação muito forte.\n",
    "# 0.7 a 0.9 positivo ou negativo indica uma correlação forte.percorre\n",
    "# 0.5 a 0.7 positivo ou negativo indica uma correlação moderada.\n",
    "# 0.3 a 0.5 positivo ou negativo indica uma correlação fraca.\n",
    "# 0 a 0.3 positivo ou negativo indica uma correlação desprezível.'''\n",
    "def corr_pearson(y, x, inlog=False):\n",
    "    if inlog:\n",
    "        y = return_varlog(y)\n",
    "        x = return_varlog(x)\n",
    "    \n",
    "    y_avg, x_avg = np.average(y), np.average(x)\n",
    "    y_stdev, x_stdev = np.std(y), np.std(x)\n",
    "    n = len(y)\n",
    "    denominator = y_stdev * x_stdev * n\n",
    "    numerator = np.sum(np.multiply(y-y_avg, x-x_avg))\n",
    "    p_coef = numerator/denominator\n",
    "    return p_coef\n",
    "\n",
    "\"\"\"\n",
    "Apply correlation in DataFrame of the pairs\n",
    "\"\"\"\n",
    "def apply_corr(data, pairs, period=250):\n",
    "    pairs['Corr'] = 0\n",
    "    \n",
    "    for i, row in pairs.iterrows():\n",
    "        y = data[row['Dependente']]\n",
    "        x = data[row['Independente']]\n",
    "        y, x = getvalues_by_period(y, x, period)\n",
    "            \n",
    "        corr = corr_pearson(y, x, True)\n",
    "        pairs['Corr'].iloc[i] = corr\n",
    "\n",
    "\"\"\"\n",
    "Check signal\n",
    "\"\"\"\n",
    "def signal(y, x):\n",
    "    model = model_ols(y, x)\n",
    "    std = statistics.stdev(model.resid)\n",
    "    resi_curr = model.resid.iloc[-1]\n",
    "    zscore_up = 2*std\n",
    "    zscore_down = -2*std\n",
    "    zcurrent = 0\n",
    "    desc = ''\n",
    "    \n",
    "    # >0; resíduo acima da linha 0\n",
    "    if(resi_curr > 0):\n",
    "        desc = 'Short/Long'\n",
    "        zcurrent = zscore_up\n",
    "    else:\n",
    "        desc = 'Long/Short'\n",
    "        zcurrent = zscore_down\n",
    "    \n",
    "    percent = (abs(resi_curr)/abs(zcurrent))\n",
    "    #1-descr\n",
    "    #2-resíduo atual\n",
    "    #3-percent distância da linha 0, quanto maior, melhor\n",
    "    return [desc, resi_curr, percent]\n",
    "\n",
    "\"\"\"\n",
    "Apply signal in DataFrame of the pairs\n",
    "\"\"\"\n",
    "def apply_signal(data, pairs, period=250):\n",
    "    pairs['Signal'] = 0\n",
    "    pairs['SignalStr'] = ''\n",
    "    \n",
    "    for i, row in pairs.iterrows():\n",
    "        y, x = getvalues_by_period(data[row['Dependente']], data[row['Independente']], period)\n",
    "        \n",
    "        sig = signal(y, x)\n",
    "        pairs['Signal'].iloc[i] = sig[2]\n",
    "        pairs['SignalStr'].iloc[i] = sig[0]\n",
    "\n",
    "\"\"\"\n",
    "Check periods\n",
    "\"\"\"\n",
    "def check_periods(data, y_symbol, x_symbol, period):\n",
    "    if (type(period) is int):\n",
    "        return check_oneperiod(data, y_symbol, x_symbol, period)\n",
    "    if (type(period) is list):\n",
    "        rows=[]\n",
    "        for p in period:\n",
    "            res = check_oneperiod(data, y_symbol, x_symbol, p)\n",
    "            rows.append([res[0], res[1]])\n",
    "        return rows\n",
    "\n",
    "\"\"\"\n",
    "Check a single period\n",
    "\"\"\"\n",
    "def check_oneperiod(data, y_symbol, x_symbol, period):\n",
    "    y, x = getvalues_by_period(data[y_symbol], data[x_symbol], period)\n",
    "    \n",
    "    adf = DickeyFuller()\n",
    "    model = model_ols(y, x)\n",
    "    adf.check(model.resid)\n",
    "    beta = model.params[1]\n",
    "\n",
    "    return [adf.p_value, adf.is_stationary]\n",
    "\n",
    "\"\"\"\n",
    "Search and return values by period\n",
    "\"\"\"\n",
    "def getvalues_by_period(y, x, period):\n",
    "    if(period <= 0):\n",
    "        return y, x\n",
    "    \n",
    "    n = len(y)\n",
    "    if(period < n):\n",
    "        pos = n-period\n",
    "        y = y.iloc[pos:]\n",
    "        x = x.iloc[pos:]\n",
    "    return y, x\n",
    "\n",
    "\"\"\"\n",
    "Standardize by z-score\n",
    "\"\"\"\n",
    "def zscore(series):\n",
    "    return (series - series.mean()) / np.std(series)\n",
    "\n",
    "\"\"\"\n",
    "Limpar pasta da imagem\n",
    "\"\"\"\n",
    "def clear_folder(pathdir):\n",
    "    for file in os.listdir(pathdir):\n",
    "        filename = '{}/{}'.format(pathdir, file)\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "\n",
    "def volatility(prices, periods=0):\n",
    "    if (periods > 0):\n",
    "        prices = prices[0:periods+1]# +1, pq haverá um lag(d-1)\n",
    "    log = np.log(prices/prices.shift(1))\n",
    "    vol = log.std() * np.sqrt(252)\n",
    "    return vol\n",
    "\n",
    "\"\"\"\n",
    "Show graphic\n",
    "\"\"\"\n",
    "def show(data, y_symbol, x_symbol, period=250, padronizar=True, savefig=''):\n",
    "    y, x = getvalues_by_period(data[y_symbol], data[x_symbol], period)\n",
    "    \n",
    "    model= model_ols(y, x)\n",
    "    result = model.resid\n",
    "    \n",
    "    # padronizar porque a taxa absoluta pode não ser a maneira mais ideal de analisar\n",
    "    if(padronizar):\n",
    "        result = zscore(model.resid)\n",
    "        \n",
    "    std = statistics.stdev(result)\n",
    "    entry_threshold = 2 # entrada em 2 desvio padrão\n",
    "    \n",
    "    result.plot(figsize=(17,6), linewidth=2)\n",
    "    plt.ylabel('Residual')\n",
    "    if(y_symbol != '' and x_symbol != ''):\n",
    "        plt.title('{} / {}'.format(y_symbol, x_symbol))\n",
    "\n",
    "    #purple\n",
    "    plt.axhline(0, color='black',label='mean') # Add the mean of residual\n",
    "    plt.axhline(entry_threshold*std, color='red', linestyle='--', linewidth=2)\n",
    "    plt.axhline(-entry_threshold*std, color='green', linestyle='--', linewidth=2)\n",
    "    plt.xlabel('')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.margins(0.1)\n",
    "    if(savefig!=''):\n",
    "        plt.savefig(savefig)\n",
    "\n",
    "    #plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_cart = 'datasets/data_cart.csv'\n",
    "path_data_full = 'datasets/data.csv'\n",
    "path_data_alpha = 'datasets/data_alpha.csv'\n",
    "path_data_yahoo = 'datasets/data_yahoo.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((312, 72), 'from 2019-05-02 to 2020-07-31')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_data_yahoo, index_col=0)\n",
    "#df = df[:-1].copy()\n",
    "data = df[df.columns.difference(['Data', 'Date'])]\n",
    "data.shape, 'from {} to {}'.format(data.index[0], data.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cointegration(data['ABEV3'], data['AZUL4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pairs = find_cointegrated_pairs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Half-Life applied successfully\n"
     ]
    }
   ],
   "source": [
    "apply_halflife(data, pairs)\n",
    "print('Half-Life applied successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurst applied successfully\n"
     ]
    }
   ],
   "source": [
    "apply_hurst(data, pairs)\n",
    "print('Hurst applied successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation applied successfully\n"
     ]
    }
   ],
   "source": [
    "apply_corr(data, pairs)\n",
    "print('Correlation applied successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal applied successfully\n"
     ]
    }
   ],
   "source": [
    "apply_signal(data, pairs)\n",
    "print('Signal applied successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_periods(data, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Dependente</th>\n",
       "      <th>Independente</th>\n",
       "      <th>Dickey-Fuller</th>\n",
       "      <th>ADF</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Std</th>\n",
       "      <th>HalfLife</th>\n",
       "      <th>Hurst</th>\n",
       "      <th>Corr</th>\n",
       "      <th>Signal</th>\n",
       "      <th>SignalStr</th>\n",
       "      <th>PeriodQt</th>\n",
       "      <th>PeriodStr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>ABEV3</td>\n",
       "      <td>AZUL4</td>\n",
       "      <td>-3.440333</td>\n",
       "      <td>95</td>\n",
       "      <td>0.223578</td>\n",
       "      <td>0.700671</td>\n",
       "      <td>16</td>\n",
       "      <td>0.413574</td>\n",
       "      <td>0.628439</td>\n",
       "      <td>0.275331</td>\n",
       "      <td>Short/Long</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>ABEV3</td>\n",
       "      <td>B3SA3</td>\n",
       "      <td>-4.770724</td>\n",
       "      <td>99</td>\n",
       "      <td>0.110709</td>\n",
       "      <td>1.729400</td>\n",
       "      <td>80</td>\n",
       "      <td>0.512848</td>\n",
       "      <td>0.580280</td>\n",
       "      <td>0.588624</td>\n",
       "      <td>Long/Short</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>ABEV3</td>\n",
       "      <td>BBAS3</td>\n",
       "      <td>-2.876998</td>\n",
       "      <td>95</td>\n",
       "      <td>0.308072</td>\n",
       "      <td>0.059457</td>\n",
       "      <td>11</td>\n",
       "      <td>0.387236</td>\n",
       "      <td>0.594132</td>\n",
       "      <td>0.029669</td>\n",
       "      <td>Short/Long</td>\n",
       "      <td>8</td>\n",
       "      <td>100,120,140,160,180,200,240,250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>ABEV3</td>\n",
       "      <td>BBDC3</td>\n",
       "      <td>-3.598407</td>\n",
       "      <td>99</td>\n",
       "      <td>0.433158</td>\n",
       "      <td>0.205531</td>\n",
       "      <td>9</td>\n",
       "      <td>0.335715</td>\n",
       "      <td>0.615399</td>\n",
       "      <td>0.102560</td>\n",
       "      <td>Short/Long</td>\n",
       "      <td>6</td>\n",
       "      <td>100,180,200,220,240,250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>ABEV3</td>\n",
       "      <td>BBDC4</td>\n",
       "      <td>-3.745538</td>\n",
       "      <td>99</td>\n",
       "      <td>0.417191</td>\n",
       "      <td>0.341320</td>\n",
       "      <td>8</td>\n",
       "      <td>0.323406</td>\n",
       "      <td>0.603756</td>\n",
       "      <td>0.170318</td>\n",
       "      <td>Short/Long</td>\n",
       "      <td>5</td>\n",
       "      <td>180,200,220,240,250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1672</td>\n",
       "      <td>250</td>\n",
       "      <td>USIM5</td>\n",
       "      <td>VIVT4</td>\n",
       "      <td>-3.516322</td>\n",
       "      <td>99</td>\n",
       "      <td>0.344083</td>\n",
       "      <td>0.792672</td>\n",
       "      <td>9</td>\n",
       "      <td>0.244058</td>\n",
       "      <td>0.391329</td>\n",
       "      <td>0.395542</td>\n",
       "      <td>Short/Long</td>\n",
       "      <td>4</td>\n",
       "      <td>200,220,240,250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1673</td>\n",
       "      <td>100</td>\n",
       "      <td>USIM5</td>\n",
       "      <td>VVAR3</td>\n",
       "      <td>-3.297732</td>\n",
       "      <td>95</td>\n",
       "      <td>0.244418</td>\n",
       "      <td>0.532990</td>\n",
       "      <td>42</td>\n",
       "      <td>0.456466</td>\n",
       "      <td>0.637285</td>\n",
       "      <td>0.293005</td>\n",
       "      <td>Long/Short</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1674</td>\n",
       "      <td>250</td>\n",
       "      <td>VALE3</td>\n",
       "      <td>VVAR3</td>\n",
       "      <td>-3.019665</td>\n",
       "      <td>95</td>\n",
       "      <td>1.107225</td>\n",
       "      <td>0.414996</td>\n",
       "      <td>7</td>\n",
       "      <td>0.329835</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>0.207082</td>\n",
       "      <td>Short/Long</td>\n",
       "      <td>5</td>\n",
       "      <td>100,140,220,240,250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>100</td>\n",
       "      <td>VIVT4</td>\n",
       "      <td>VVAR3</td>\n",
       "      <td>-3.771610</td>\n",
       "      <td>99</td>\n",
       "      <td>-0.009969</td>\n",
       "      <td>1.543259</td>\n",
       "      <td>17</td>\n",
       "      <td>0.248407</td>\n",
       "      <td>0.451457</td>\n",
       "      <td>0.139629</td>\n",
       "      <td>Long/Short</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1676</td>\n",
       "      <td>100</td>\n",
       "      <td>VIVT4</td>\n",
       "      <td>WEGE3</td>\n",
       "      <td>-3.773101</td>\n",
       "      <td>99</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>1.490848</td>\n",
       "      <td>15</td>\n",
       "      <td>0.307907</td>\n",
       "      <td>0.331182</td>\n",
       "      <td>0.279819</td>\n",
       "      <td>Short/Long</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1677 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Period Dependente Independente  Dickey-Fuller  ADF      Beta       Std  \\\n",
       "0        100      ABEV3        AZUL4      -3.440333   95  0.223578  0.700671   \n",
       "1        100      ABEV3        B3SA3      -4.770724   99  0.110709  1.729400   \n",
       "2        250      ABEV3        BBAS3      -2.876998   95  0.308072  0.059457   \n",
       "3        250      ABEV3        BBDC3      -3.598407   99  0.433158  0.205531   \n",
       "4        250      ABEV3        BBDC4      -3.745538   99  0.417191  0.341320   \n",
       "...      ...        ...          ...            ...  ...       ...       ...   \n",
       "1672     250      USIM5        VIVT4      -3.516322   99  0.344083  0.792672   \n",
       "1673     100      USIM5        VVAR3      -3.297732   95  0.244418  0.532990   \n",
       "1674     250      VALE3        VVAR3      -3.019665   95  1.107225  0.414996   \n",
       "1675     100      VIVT4        VVAR3      -3.771610   99 -0.009969  1.543259   \n",
       "1676     100      VIVT4        WEGE3      -3.773101   99  0.001507  1.490848   \n",
       "\n",
       "      HalfLife     Hurst      Corr    Signal   SignalStr  PeriodQt  \\\n",
       "0           16  0.413574  0.628439  0.275331  Short/Long         1   \n",
       "1           80  0.512848  0.580280  0.588624  Long/Short         1   \n",
       "2           11  0.387236  0.594132  0.029669  Short/Long         8   \n",
       "3            9  0.335715  0.615399  0.102560  Short/Long         6   \n",
       "4            8  0.323406  0.603756  0.170318  Short/Long         5   \n",
       "...        ...       ...       ...       ...         ...       ...   \n",
       "1672         9  0.244058  0.391329  0.395542  Short/Long         4   \n",
       "1673        42  0.456466  0.637285  0.293005  Long/Short         1   \n",
       "1674         7  0.329835  0.525860  0.207082  Short/Long         5   \n",
       "1675        17  0.248407  0.451457  0.139629  Long/Short         1   \n",
       "1676        15  0.307907  0.331182  0.279819  Short/Long         1   \n",
       "\n",
       "                            PeriodStr  \n",
       "0                                 100  \n",
       "1                                 100  \n",
       "2     100,120,140,160,180,200,240,250  \n",
       "3             100,180,200,220,240,250  \n",
       "4                 180,200,220,240,250  \n",
       "...                               ...  \n",
       "1672                  200,220,240,250  \n",
       "1673                              100  \n",
       "1674              100,140,220,240,250  \n",
       "1675                              100  \n",
       "1676                              100  \n",
       "\n",
       "[1677 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved successfully!!!\n"
     ]
    }
   ],
   "source": [
    "pairs.to_csv('datasets/cointegrated_pairs.csv', index=False)\n",
    "print('Saved successfully!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo\n",
    "Agora é só usar o cointegrated_pairs.csv para fazer as diversas análises que desejar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.read_csv('datasets/cointegrated_pairs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

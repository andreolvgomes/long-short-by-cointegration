{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@constandinou.antonio/quant-post-3-1-a-guided-path-into-mean-reversion-8b33b3c279e4\n",
    "#https://medium.com/@bart.chr/pairs-trading-for-algorithmic-trading-breakdown-d8b709f59372\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import statsmodels.tsa.stattools as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    5.796933\n",
      "x        0.732486\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fit and summarize OLS model\n",
    "model = sm.OLS(y, x).fit()\n",
    "print(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@bart.chr/pairs-trading-for-algorithmic-trading-breakdown-d8b709f59372\n",
    "#https://github.com/aconstandinou/mean-reversion\n",
    "class ADF(object):\n",
    "    \"\"\"\n",
    "    Augmented Dickeyâ€“Fuller (ADF) unit root test\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.p_value = None\n",
    "        self.five_perc_stat = None\n",
    "        self.perc_stat = None\n",
    "        self.p_min = .0\n",
    "        self.p_max = .05\n",
    "        self.look_back = 63\n",
    "\n",
    "    def apply_adf(self, time_series):\n",
    "        model = ts.adfuller(time_series, 1)\n",
    "        self.p_value = model[1]\n",
    "        self.five_perc_stat = model[4]['5%']\n",
    "        self.perc_stat = model[0]\n",
    "\n",
    "    def use_P(self):\n",
    "        return (self.p_value > self.p_min) and (self.p_value < self.p_max)\n",
    "    \n",
    "    def use_critical(self):\n",
    "        return abs(self.perc_stat) > abs(self.five_perc_stat)\n",
    "\n",
    "class Half_Life(object):\n",
    "    \"\"\"\n",
    "    Half Life test from the Ornstein-Uhlenbeck process \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.hl_min = 1.0\n",
    "        self.hl_max = 42.0\n",
    "        self.look_back = 43\n",
    "        self.half_life = None\n",
    "\n",
    "    def apply_half_life(self, time_series):\n",
    "        lag = np.roll(time_series, 1)\n",
    "        lag[0] = 0\n",
    "        ret = time_series - lag\n",
    "        ret[0] = 0\n",
    "\n",
    "        # adds intercept terms to X variable for regression\n",
    "        lag2 = sm.add_constant(lag)\n",
    "        model = sm.OLS(ret, lag2)\n",
    "        res = model.fit()\n",
    "        \n",
    "        #self.half_life = round(-np.log(2) / res.params[1], 0)\n",
    "        self.half_life = -np.log(2) / res.params[1]\n",
    "\n",
    "    def use(self):\n",
    "        return (self.half_life < self.hl_max) and (self.half_life > self.hl_min)\n",
    "\n",
    "def half_life(spread):\n",
    "    spread_lag = spread.shift(1)\n",
    "    spread_lag.iloc[0] = spread_lag.iloc[1]\n",
    "\n",
    "    spread_ret = spread - spread_lag\n",
    "    spread_ret.iloc[0] = spread_ret.iloc[1]\n",
    "\n",
    "    spread_lag2 = sm.add_constant(spread_lag)\n",
    "    model = sm.OLS(spread_ret,spread_lag2)\n",
    "    res = model.fit()\n",
    "    \n",
    "    halflife = int(round(-np.log(2) / res.params[1],0))\n",
    "\n",
    "    if halflife <= 0:\n",
    "        halflife = 1\n",
    "    return halflife \n",
    "\n",
    "# a value > 0.5 indicates a trending time series. The greater the value above 0.5 the more trending it is.\n",
    "# a value = 0.5 indicates a random walk.\n",
    "# a value < 0.5 indicates a mean reverting time series. The closer the value gets to 0 the more mean reverting it is\n",
    "class Hurst():\n",
    "    \"\"\"\n",
    "    If Hurst Exponent is under the 0.5 value of a random walk, then the series is mean reverting\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.h_min = 0.0\n",
    "        self.h_max = 0.4\n",
    "        self.look_back = 126\n",
    "        #https://robotwealth.com/demystifying-the-hurst-exponent-part-1/\n",
    "        self.lag_max = 20#era 100\n",
    "        self.h_value = None\n",
    "    \n",
    "    def apply_hurst(self, time_series):\n",
    "        lags = range(2, self.lag_max)\n",
    "\n",
    "        tau = [np.sqrt(np.std(np.subtract(time_series[lag:], time_series[:-lag]))) for lag in lags]\n",
    "\n",
    "        #poly = np.polyfit(np.log10(lags), np.log10(tau), 1)\n",
    "        poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "\n",
    "        self.h_value = poly[0]*2.0 \n",
    "\n",
    "    def use(self):\n",
    "        return (self.h_value < self.h_max) and (self.h_value > self.h_min)\n",
    "    \n",
    "def hurst_ernie_chan(p):\n",
    "    lags = range(2, 20)\n",
    "    variancetau = []; tau = []\n",
    "    for lag in lags: \n",
    "        #  Write the different lags into a vector to compute a set of tau or lags\n",
    "        tau.append(lag)\n",
    "\n",
    "        # Compute the log returns on all days, then compute the variance on the difference in log returns\n",
    "        # call this pp or the price difference\n",
    "        pp = np.subtract(p[lag:], p[:-lag])\n",
    "        variancetau.append(np.var(pp))\n",
    "\n",
    "    # we now have a set of tau or lags and a corresponding set of variances.\n",
    "    # plot the log of those variance against the log of tau and get the slope\n",
    "    m = np.polyfit(np.log10(tau),np.log10(variancetau),1)\n",
    "\n",
    "    hurst = m[0] / 2\n",
    "\n",
    "    return hurst\n",
    "\n",
    "def model_ols(y, x):\n",
    "    x = sm.add_constant(x)\n",
    "    model = sm.OLS(y, x).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "life = Half_Life()\n",
    "life.apply_half_life(model.resid)\n",
    "print(life.use())\n",
    "print(life.half_life)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ADF' object has no attribute 'check'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-3a65fbfcf16b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0madf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mADF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0madf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_P\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_critical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ADF' object has no attribute 'check'"
     ]
    }
   ],
   "source": [
    "adf = ADF()\n",
    "adf.check(model.resid)\n",
    "print(adf.use_P())\n",
    "print(adf.use_critical())\n",
    "print(adf.p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.2642154672334072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "hurst = Hurst()\n",
    "hurst.apply_hurst(model.resid.as_matrix())\n",
    "print(hurst.use())\n",
    "print(hurst.h_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

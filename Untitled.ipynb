{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.quantinsti.com/kalman-filter-techniques-statistical-arbitrage-china-futures-market-python/\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "from pykalman import KalmanFilter\n",
    "from datetime import datetime\n",
    "from numpy import log, polyfit, sqrt, std, subtract\n",
    "import statsmodels.tsa.stattools as ts\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "def load_data():\n",
    "    # set the working directory\n",
    "    import os\n",
    "    #os.getcwd() # this is to check the current working directory\n",
    "    #os.chdir(\"D://EPAT//09 FP//\")\n",
    "    all_contracts = pd.read_csv('datasets/data.csv',parse_dates=True)\n",
    "    p_sorted = pd.read_csv('datasets/data.csv',parse_dates=False)\n",
    "    \n",
    "    df_all = all_contracts[all_contracts.columns.difference(['Data'])]\n",
    "    df_all = df_all[df_all.columns[0:10]]\n",
    "    \n",
    "    dfp = p_sorted[p_sorted.columns.difference(['Data'])]\n",
    "    dfp = dfp[dfp.columns[0:10]]\n",
    "    \n",
    "    return df_all, dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df2 = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cointegrated Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cointegrated_pairs(dataframe, critial_level = 0.05):\n",
    "    n = dataframe.shape[1] # the length of dateframe\n",
    "    pvalue_matrix = np.ones((n, n)) # initialize the matrix of p\n",
    "    keys = dataframe.keys() # get the column names\n",
    "    pairs = [] # initilize the list for cointegration\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n): # for j bigger than i\n",
    "            if (i == j): continue\n",
    "            stock1 = dataframe[keys[i]] # obtain the price of two contract\n",
    "            stock2 = dataframe[keys[j]]\n",
    "            result = sm.tsa.stattools.coint(stock1, stock2) # get conintegration\n",
    "            pvalue = result[1] # get the pvalue\n",
    "            pvalue_matrix[i, j] = pvalue\n",
    "            \n",
    "            if pvalue < critial_level: # if p-value less than the critical level\n",
    "                pairs.append((keys[i], keys[j], pvalue)) # record the contract with that p-value\n",
    "                \n",
    "    return pvalue_matrix, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AALR3', 'ALSO3', 0.020715617740505447), ('AALR3', 'ALUP11', 0.04252175353504194), ('ABCB4', 'ALPA3', 0.009872962526964044), ('ABCB4', 'ALPA4', 0.0039592615460065945), ('ABCB4', 'ALUP11', 0.00030189871799101656), ('ALPA3', 'ALPA4', 0.0007083545442865279), ('ALPA3', 'ALUP11', 0.005118628491249124), ('ALPA4', 'ALSO3', 0.03556947532715038), ('ALPA4', 'ALUP11', 0.01142543528960278)]\n"
     ]
    }
   ],
   "source": [
    "pvalue_matrix, pairs = find_cointegrated_pairs(df)\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KalmanFilterAverage(x):\n",
    "    # Construct a Kalman filter\n",
    "    from pykalman import KalmanFilter\n",
    "    kf = KalmanFilter(transition_matrices = [1],\n",
    "     observation_matrices = [1],\n",
    "     initial_state_mean = 0,\n",
    "     initial_state_covariance = 1,\n",
    "     observation_covariance=1,\n",
    "     transition_covariance=.01)\n",
    "\n",
    "    # Use the observed values of the price to get a rolling mean\n",
    "    state_means, _ = kf.filter(x.values)\n",
    "    state_means = pd.Series(state_means.flatten(), index=x.index)\n",
    "    return state_means\n",
    "\n",
    "# Kalman filter regression\n",
    "def KalmanFilterRegression(x,y):\n",
    "    delta = 1e-3\n",
    "    trans_cov = delta / (1 - delta) * np.eye(2) # How much random walk wiggles\n",
    "    obs_mat = np.expand_dims(np.vstack([[x], [np.ones(len(x))]]).T, axis=1)\n",
    "\n",
    "    kf = KalmanFilter(n_dim_obs=1, n_dim_state=2, # y is 1-dimensional, (alpha, beta) is 2-dimensional\n",
    "     initial_state_mean=[0,0],\n",
    "     initial_state_covariance=np.ones((2, 2)),\n",
    "     transition_matrices=np.eye(2),\n",
    "     observation_matrices=obs_mat,\n",
    "     observation_covariance=2,\n",
    "     transition_covariance=trans_cov)\n",
    "    # Use the observations y to get running estimates and errors for the state parameters\n",
    "    state_means, state_covs = kf.filter(y.values)\n",
    "    return state_means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hurst exponent and Half-life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_life(spread):\n",
    "    spread_lag = spread.shift(1)\n",
    "    spread_lag.iloc[0] = spread_lag.iloc[1]\n",
    "    spread_ret = spread - spread_lag\n",
    "    spread_ret.iloc[0] = spread_ret.iloc[1]\n",
    "    spread_lag2 = sm.add_constant(spread_lag)\n",
    "    model = sm.OLS(spread_ret,spread_lag2)\n",
    "    res = model.fit()\n",
    "    halflife = int(round(-np.log(2) / res.params[1],0))\n",
    "\n",
    "    if halflife <= 0:\n",
    "        halflife = 1\n",
    "    return halflife"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-test Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(s1, s2, x, y):\n",
    "    #############################################################\n",
    "    # INPUT:\n",
    "    # s1: the symbol of contract one\n",
    "    # s2: the symbol of contract two\n",
    "    # x: the price series of contract one\n",
    "    # y: the price series of contract two\n",
    "    # OUTPUT:\n",
    "    # df1['cum rets']: cumulative returns in pandas data frame\n",
    "    # sharpe: sharpe ratio\n",
    "    # CAGR: CAGR\n",
    "    # run regression to find hedge ratio and then create spread series\n",
    "    df1 = pd.DataFrame({'y':y,'x':x})\n",
    "    state_means = KalmanFilterRegression(KalmanFilterAverage(x),KalmanFilterAverage(y))\n",
    "\n",
    "    df1['hr'] = - state_means[:,0]\n",
    "    df1['spread'] = df1.y + (df1.x * df1.hr)\n",
    "    \n",
    "    # calculate half life\n",
    "    halflife = half_life(df1['spread'])\n",
    "    \n",
    "    # calculate z-score with window = half life period\n",
    "    meanSpread = df1.spread.rolling(window=halflife).mean()\n",
    "    stdSpread = df1.spread.rolling(window=halflife).std()\n",
    "    df1['zScore'] = (df1.spread-meanSpread)/stdSpread\n",
    "    ##############################################################\n",
    "    # trading logic\n",
    "    entryZscore = 2\n",
    "    exitZscore = 0\n",
    "    #set up num units long\n",
    "    df1['long entry'] = ((df1.zScore < - entryZscore) & ( df1.zScore.shift(1) > - entryZscore))\n",
    "    df1['long exit'] = ((df1.zScore > - exitZscore) & (df1.zScore.shift(1) < - exitZscore)) \n",
    "    df1['num units long'] = np.nan \n",
    "    df1.loc[df1['long entry'],'num units long'] = 1 \n",
    "    df1.loc[df1['long exit'],'num units long'] = 0 \n",
    "    df1['num units long'][0] = 0 \n",
    "    #set up num units short \n",
    "    df1['short entry'] = ((df1.zScore > entryZscore) & ( df1.zScore.shift(1) < entryZscore))\n",
    "    df1['num units long'] = df1['num units long'].fillna(method='pad')\n",
    "    df1['short exit'] = ((df1.zScore < exitZscore) & (df1.zScore.shift(1) > exitZscore))\n",
    "    df1.loc[df1['short entry'],'num units short'] = -1\n",
    "    df1.loc[df1['short exit'],'num units short'] = 0\n",
    "    df1['num units short'][0] = 0\n",
    "    df1['num units short'] = df1['num units short'].fillna(method='pad')\n",
    "\n",
    "    df1['numUnits'] = df1['num units long'] + df1['num units short']\n",
    "    df1['spread pct ch'] = (df1['spread'] - df1['spread'].shift(1)) / ((df1['x'] * abs(df1['hr'])) + df1['y'])\n",
    "    df1['port rets'] = df1['spread pct ch'] * df1['numUnits'].shift(1)\n",
    "\n",
    "    df1['cum rets'] = df1['port rets'].cumsum()\n",
    "    df1['cum rets'] = df1['cum rets'] + 1\n",
    "\n",
    "    name = \"bt\"+ s1 + \"-\" + s2 + \".csv\"\n",
    "    df1.to_csv(name)\n",
    "    ##############################################################\n",
    "\n",
    "    try:\n",
    "        sharpe = ((df1['port rets'].mean() / df1['port rets'].std()) * sqrt(252))\n",
    "    except ZeroDivisionError:\n",
    "        sharpe = 0.0\n",
    "    ##############################################################\n",
    "    start_val = 1\n",
    "    end_val = df1['cum rets'].iat[-1]\n",
    "\n",
    "    start_date = df1.iloc[0].name\n",
    "    end_date = df1.iloc[-1].name\n",
    "    days = (end_date - start_date).days\n",
    "\n",
    "    CAGR = round(((float(end_val) / float(start_val)) ** (252.0/days)) - 1,4)\n",
    "\n",
    "    return df1['cum rets'], sharpe, CAGR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0     NaN\n",
       " 1     1.0\n",
       " 2     1.0\n",
       " 3     1.0\n",
       " 4     1.0\n",
       "      ... \n",
       " 87    1.0\n",
       " 88    1.0\n",
       " 89    1.0\n",
       " 90    1.0\n",
       " 91    1.0\n",
       " Name: cum rets, Length: 92, dtype: float64, 0.0, 0.0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest('AALR3', 'ALSO3', df['AALR3'], df['ALSO3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
